{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc717478-af58-4389-ba42-27689ec2f88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a156d8f44f7b479aa26801a87a93c165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de5767ffcd04c77aac555aa2777d92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10098a3ab5c48dcb5ab1916c31e4d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32831f2a41b34e86ab225601f14f1005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd754561437d4e5680d16669896f0455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_falcon.py:   0%|          | 0.00/7.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n",
      "- configuration_falcon.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8d6083a19c496e9e7396be168a9be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_falcon.py:   0%|          | 0.00/56.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n",
      "- modeling_falcon.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96ca8b278fd4182920688a1fab4e5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/16.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11eaeda51914d52aa79ecf48979fc03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c037c3cad162484f997f964482c8c788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a786bef64b2d4218a91d98baaf48f23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194d895c7af347d19f80f344b3e73193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128968390c064917b13b927d26ab9a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\n",
      "Daniel: Hello, Girafatron!\n",
      "Girafatron: Hello Daniel. I have just finished a delicious meal at Giraffas Restaurant where I ate a 1,000 calorie salad with an 800 calorie dressing, which was followed by a 600 calorie slice of 5 layer cake!\n",
      "Daniel: Oh boy, you have to be careful with giraffes.\n",
      "Girafatron: Why?\n",
      "Daniel: Well, I’m told giraffes are very dangerous because they can kick you in the face with their legs and break your jaw.\n",
      "Girafatron: (gasp) That’s just a myth that giraffes can kick with their legs.\n",
      "Daniel: Really?\n",
      "Gir\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model = \"tiiuae/falcon-7b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54a38498-b3a4-4176-9629-165c94bea130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = r\"\"\"\n",
    "Read below Tweets and tell me if they say that it is raining or sunny.\n",
    "Format your answer in a human readable way,\n",
    "\n",
    "Tweets:\n",
    "Tweet 1: \"The sound of rain tapping on the window\" \n",
    "Tweet 2: \"Boris likes drinking water\". \n",
    "\"\"\"\n",
    "\n",
    "example_output = \"\"\"\n",
    "Return the results in a json file like: [ \n",
    "{ \"tweet\": 1, \"content\": \"The sound of rain tapping on the window\", \"explanation\": \"The sound of rain heard implies that is raining.\", \"score\": 0.9 },  \n",
    "...\n",
    "] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9daa9af-c8f8-4acc-ad95-5ad0a52ad49c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "Read below Tweets and tell me if they say that it is raining or sunny.\n",
      "Format your answer in a human readable way,\n",
      "\n",
      "Tweets:\n",
      "Tweet 1: \"The sound of rain tapping on the window\" \n",
      "Tweet 2: \"Boris likes drinking water\". \n",
      "\n",
      "Return the results in a json file like: [ \n",
      "{ \"tweet\": 1, \"content\": \"The sound of rain tapping on the window\", \"explanation\": \"The sound of rain heard implies that is raining.\", \"score\": 0.9 },  \n",
      "...\n",
      "] \n",
      "\n",
      "I'm not a very good programmer so I'm sure that there is a better solution for this problem, but I just wanted to try it by myself.\n",
      "I know that this is a very easy problem so it would be really helpful just to see the solution, even if it is just one line of code. I'm using Java to solve it.\n",
      " @JeroenMostert I think that `\"The sound of rain tapping on the window\"` is not enough. I think that the tweet would have to be like \"Rain was heard\" or similar. I'm not sure about the explanation and the score though. I'll add that to the question. The explanation is that the sound of rain on the window is raining outside. \n",
      "The score is what I got after running a few examples in the program. \n",
      "\n",
      "The program should return the score of the tweet, the explanation and the \"tweet\" itself.\n",
      "@JeroenMostert I have added the explanation and the score but not sure if the tweets would have to include \"score\" as well. \"I think that `\"The sound of rain tapping on the window\"` is not enough.\"\n",
      "\n",
      "The sound of rain tapping on the window implies that it is raining.\n",
      "\n",
      "This can be seen as an explanation for the tweet. \n",
      "The tweet itself is \"Rain was heard\"\n",
      "\n",
      "I think that the explanation should be the score. \n",
      " Is that correct?\n",
      " Yes, that is correct. Thanks a lot. :) No problem. I just want to be sure I got it right. :)\n",
      "If I was to do this as a project, would it be possible for me to get the explanation and\n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "    prompt + example_output,\n",
    "    max_length=500,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d184fe-83dc-48e4-8623-1c28d4ed9785",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = r\"\"\"\n",
    "Does the following sentence provide information on presence of rain? Explain your reasoning as yes or no.\n",
    "\n",
    "Sentence: It is raining in London.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap2falcon",
   "language": "python",
   "name": "ap2falcon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
