{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc717478-af58-4389-ba42-27689ec2f88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e854b0186dd84dad886cc1819e6c2c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model = \"tiiuae/falcon-7b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54a38498-b3a4-4176-9629-165c94bea130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = r\"\"\"\n",
    "Read below Tweets and tell me if they say that it is raining or sunny.\n",
    "Format your answer in a human readable way,\n",
    "\n",
    "Tweets:\n",
    "Tweet 1: \"The sound of rain tapping on the window\" \n",
    "Tweet 2: \"Boris likes drinking water\". \n",
    "\"\"\"\n",
    "\n",
    "example_output = \"\"\"\n",
    "Return the results in a json file like: [ \n",
    "{ \"tweet\": 1, \"content\": \"The sound of rain tapping on the window\", \"explanation\": \"The sound of rain heard implies that is raining.\", \"score\": 0.9 },  \n",
    "...\n",
    "] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9daa9af-c8f8-4acc-ad95-5ad0a52ad49c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "Read below Tweets and tell me if they say that it is raining or sunny.\n",
      "Format your answer in a human readable way,\n",
      "\n",
      "Tweets:\n",
      "Tweet 1: \"The sound of rain tapping on the window\" \n",
      "Tweet 2: \"Boris likes drinking water\". \n",
      "\n",
      "Return the results in a json file like: [ \n",
      "{ \"tweet\": 1, \"content\": \"The sound of rain tapping on the window\", \"explanation\": \"The sound of rain heard implies that is raining.\", \"score\": 0.9 },  \n",
      "...\n",
      "] \n",
      "\n",
      "I'm not a very good programmer so I'm sure that there is a better solution for this problem, but I just wanted to try it by myself.\n",
      "I know that this is a very easy problem so it would be really helpful just to see the solution, even if it is just one line of code. I'm using Java to solve it.\n",
      " @JeroenMostert I think that `\"The sound of rain tapping on the window\"` is not enough. I think that the tweet would have to be like \"Rain was heard\" or similar. I'm not sure about the explanation and the score though. I'll add that to the question. The explanation is that the sound of rain on the window is raining outside. \n",
      "The score is what I got after running a few examples in the program. \n",
      "\n",
      "The program should return the score of the tweet, the explanation and the \"tweet\" itself.\n",
      "@JeroenMostert I have added the explanation and the score but not sure if the tweets would have to include \"score\" as well. \"I think that `\"The sound of rain tapping on the window\"` is not enough.\"\n",
      "\n",
      "The sound of rain tapping on the window implies that it is raining.\n",
      "\n",
      "This can be seen as an explanation for the tweet. \n",
      "The tweet itself is \"Rain was heard\"\n",
      "\n",
      "I think that the explanation should be the score. \n",
      " Is that correct?\n",
      " Yes, that is correct. Thanks a lot. :) No problem. I just want to be sure I got it right. :)\n",
      "If I was to do this as a project, would it be possible for me to get the explanation and\n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "    prompt + example_output,\n",
    "    max_length=500,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d184fe-83dc-48e4-8623-1c28d4ed9785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = r\"\"\"\n",
    "Does the following sentence provide information on presence of rain? Explain your reasoning as yes or no.\n",
    "\n",
    "Sentence: It is raining in London.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f8c9fd7-b8cb-45a9-87f1-0a5b77b3950a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "Does the following sentence provide information on presence of rain? Explain your reasoning as yes or no.\n",
      "\n",
      "Sentence: It is raining in London.\n",
      "\n",
      "It is raining in London.\n",
      "\n",
      "It is raining in the capital of the UK.\n",
      "\n",
      " No, because there is no way to know whether the capital of the UK is London or some other capital.\n",
      "The correct answer would be: There's a 100% chance that it is raining in the capital of the UK.\n",
      " No it doesn't, since it's not a complete sentence. For example, you can use the same phrase to describe a person: \"The person has arrived\". It's just a matter of using the proper word order.\n",
      "The correct answer will vary depending on the context.\n",
      " @Tᴚoɯɐuo: If there is no context, it means *There is nothing to say about **London**.*,\n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "    prompt,\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf03e72-7a79-4f8f-939d-190e2c998cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap2falcon",
   "language": "python",
   "name": "ap2falcon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
